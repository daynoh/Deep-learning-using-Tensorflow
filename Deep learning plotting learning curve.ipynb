{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Customer_churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(labels = ['CustomerId','Surname','RowNumber'],axis =1)\n",
    "y = dataset['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 11), (10000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string values into numerical values\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0  Female   42       2       0.00              1   \n",
       "1          608          2  Female   41       1   83807.86              1   \n",
       "2          502          0  Female   42       8  159660.80              3   \n",
       "3          699          0  Female   39       1       0.00              2   \n",
       "4          850          2  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1 = LabelEncoder()\n",
    "X['Geography'] = label1.fit_transform(X['Geography'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = LabelEncoder()\n",
    "X['Gender'] = label.fit_transform(X['Gender'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Geography'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c984e484b9b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# one hot encoding so that the models do not think of them as meaning degree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Geography'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes_to_encode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Geography'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# one hot encoding so that the models do not think of them as meaning degree\n",
    "X = pd.get_dummies(X, drop_first = True, columns = ['Geography'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very high variance in data is never recommended over the dataset \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2 ,random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.24021723, -1.09665089,  0.77986083, ...,  1.97686   ,\n",
       "        -0.57812007, -0.57504086],\n",
       "       [ 0.75974873,  0.91186722, -0.27382717, ..., -0.50585272,\n",
       "         1.72974448, -0.57504086],\n",
       "       [-1.72725557, -1.09665089, -0.9443559 , ..., -0.50585272,\n",
       "        -0.57812007, -0.57504086],\n",
       "       ...,\n",
       "       [-0.51484098,  0.91186722,  0.87565065, ...,  1.97686   ,\n",
       "         1.72974448, -0.57504086],\n",
       "       [ 0.73902369, -1.09665089, -0.36961699, ..., -0.50585272,\n",
       "        -0.57812007, -0.57504086],\n",
       "       [ 0.95663657,  0.91186722, -1.32751517, ..., -0.50585272,\n",
       "        -0.57812007,  1.73900686]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X.shape[1], activation = 'relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 6s 884us/sample - loss: 0.0960 - accuracy: 0.9664 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 4s 609us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.3376e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 4s 559us/sample - loss: 2.8664e-04 - accuracy: 1.0000 - val_loss: 1.5800e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 4s 607us/sample - loss: 1.2245e-04 - accuracy: 1.0000 - val_loss: 7.7323e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 3s 525us/sample - loss: 6.3802e-05 - accuracy: 1.0000 - val_loss: 4.3340e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 3s 502us/sample - loss: 3.6675e-05 - accuracy: 1.0000 - val_loss: 2.6678e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 3s 517us/sample - loss: 2.2255e-05 - accuracy: 1.0000 - val_loss: 1.6847e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 4s 613us/sample - loss: 1.4075e-05 - accuracy: 1.0000 - val_loss: 1.0883e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 4s 631us/sample - loss: 9.1675e-06 - accuracy: 1.0000 - val_loss: 7.1569e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 4s 588us/sample - loss: 6.0802e-06 - accuracy: 1.0000 - val_loss: 4.7927e-06 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# if train is pandas/numpy array then also should y\n",
    "history = model.fit(X_train,y_train.to_numpy(),batch_size = 10, epochs = 10, verbose = 1, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 164us/sample - loss: 2.1323e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1322765323006365e-07, 1.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1593,    0],\n",
       "       [   0,  407]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting learning curve and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module tensorflow.python.keras.engine.sequential object:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.training.Model)\n",
      " |  Sequential(layers=None, name=None)\n",
      " |  \n",
      " |  Linear stack of layers.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      layers: list of layers to add to the model.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  # Afterwards, we do automatic shape inference:\n",
      " |  model.add(Dense(32))\n",
      " |  \n",
      " |  # This is identical to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_dim=500))\n",
      " |  \n",
      " |  # And to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      " |  \n",
      " |  # Note that you can also omit the `input_shape` argument:\n",
      " |  # In that case the model gets built the first time you call `fit` (or other\n",
      " |  # training and evaluation methods).\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.compile(optimizer=optimizer, loss=loss)\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  \n",
      " |  # Note that when using this delayed-build pattern (no input shape specified),\n",
      " |  # the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns []\n",
      " |  \n",
      " |  # Whereas if you specify the input shape, the model gets built continuously\n",
      " |  # as you are adding layers:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling `build(batch_input_shape)`:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.build((None, 500))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.network.Network\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the network's input specs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, distribute=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |              `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective\n",
      " |              function is any callable with the signature\n",
      " |              `scalar_loss = fn(y_true, y_pred)`. If the model has multiple\n",
      " |              outputs, you can use a different loss on each output by passing a\n",
      " |              dictionary or a list of losses. The loss value that will be\n",
      " |              minimized by the model will then be the sum of all individual\n",
      " |              losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |              and testing. Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          distribute: NOT SUPPORTED IN TF 2.0, please create and compile the\n",
      " |              model under distribution strategy scope instead of passing it to\n",
      " |              compile.\n",
      " |          **kwargs: Any additional arguments.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely).\n",
      " |            If `x` is a dataset, generator or\n",
      " |            `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      " |            targets will be obtained from the iterator/dataset).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, instead pass\n",
      " |              sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |              If x is a `tf.data` dataset and `steps` is\n",
      " |              None, 'evaluate' will run until the dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.evaluate, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample weights)`.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given below.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, datasets,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` could be provided.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted. In the\n",
      " |              case of a infinite dataset, it will run into a infinite loop.\n",
      " |              If 'validation_steps' is specified and only part of the dataset\n",
      " |              will be consumed, the evaluation will start from the beginning of\n",
      " |              the dataset at each epoch. This ensures that the same validation\n",
      " |              samples are used every time.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |          **kwargs: Used for backwards compatibility.\n",
      " |      \n",
      " |      Unpacking behavior for iterator-like inputs:\n",
      " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
      " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
      " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
      " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      " |        second and third elements will be used for y and sample_weight\n",
      " |        respectively. Any other type provided will be wrapped in a length one\n",
      " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      " |        should still adhere to the top-level tuple structure.\n",
      " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      " |        features, targets, and weights from the keys of a single dict.\n",
      " |          A notable unsupported data type is the namedtuple. The reason is that\n",
      " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
      " |        datatype (dict). So given a namedtuple of the form:\n",
      " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      " |        it is ambiguous whether to reverse the order of the elements when\n",
      " |        interpreting the value. Even worse is a tuple of the form:\n",
      " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      " |        and sample_weight or passed through as a single element to `x`. As a\n",
      " |        result the data processing code will simply raise a ValueError if it\n",
      " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.fit, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
      " |        this endpoint.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
      " |      \n",
      " |      If `by_name` is False weights are loaded based on the network's\n",
      " |      topology. This means the architecture should be the same as when the weights\n",
      " |      were saved.  Note that layers that don't have weights are not taken into\n",
      " |      account in the topological ordering, so adding or removing layers is fine as\n",
      " |      long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
      " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
      " |      from the TensorFlow format. Note that topological loading differs slightly\n",
      " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
      " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
      " |      TensorFlow format loads based on the object-local names of attributes to\n",
      " |      which layers are assigned in the `Model`'s constructor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the weights file to load. For weight files in\n",
      " |              TensorFlow format, this is the file prefix (the same as was passed\n",
      " |              to `save_weights`).\n",
      " |          by_name: Boolean, whether to load weights by name or by topological\n",
      " |              order. Only topological loading is supported for weight files in\n",
      " |              TensorFlow format.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
      " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
      " |              the weight (only valid when `by_name=True`).\n",
      " |      \n",
      " |      Returns:\n",
      " |          When loading a weight file in TensorFlow format, returns the same status\n",
      " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
      " |          ops are run automatically as soon as the network is built (on first call\n",
      " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
      " |          already built).\n",
      " |      \n",
      " |          When loading weights in HDF5 format, returns `None`.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available and the weight file is in HDF5\n",
      " |              format.\n",
      " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
      " |            `False`.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |            A more detailed description of unpacking behavior for iterator types\n",
      " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
      " |            for iterator-like inputs` section of `Model.fit`.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
      " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
      " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
      " |      three methods.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use Model.predict, which supports generators.\n",
      " |      \n",
      " |      DEPRECATED:\n",
      " |        `Model.predict` now supports generators, so there is no longer any need\n",
      " |        to use this endpoint.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of metrics.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset `y` should\n",
      " |            not be specified (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |              supported when `x` is a dataset.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, `y` should not be specified\n",
      " |            (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample. In this case you should make sure to specify\n",
      " |            sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |            supported when `x` is a dataset.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  sample_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model` is a compiled model ready to be used\n",
      " |      (unless the saved model was never compiled in the first place).\n",
      " |      \n",
      " |      Models built with the Sequential and Functional API can be saved to both the\n",
      " |      HDF5 and SavedModel formats. Subclassed models can only be saved with the\n",
      " |      SavedModel format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      " |              to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X, and\n",
      " |              'h5' in TF 1.X.\n",
      " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
      " |              'tf' format only. Please see the `signatures` argument in\n",
      " |              `tf.saved_model.save` for details.\n",
      " |          options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
      " |              options for saving to SavedModel.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/guide/checkpoint) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the file to save the weights to. When saving\n",
      " |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      " |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      " |              weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.08516484571615365,\n",
       "  0.0005452791132302082,\n",
       "  0.00014575729045986918,\n",
       "  6.131942065735529e-05,\n",
       "  3.0792047524528244e-05,\n",
       "  1.6903501095555384e-05,\n",
       "  9.782167135341524e-06,\n",
       "  5.8420792771940456e-06,\n",
       "  3.5497228430614315e-06,\n",
       "  2.187665520452242e-06],\n",
       " 'accuracy': [0.9695, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot confusion matrix we use mlextend and the learning curve at each epoch\n",
    "history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "# plotting training and validation loss values\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrix import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 576x576 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x2498ab7a888>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(y_test,y_pred)\n",
    "plot_confusion_matrix(conf_mat = mat, figsize= (8,8),class_names=['stay','exit'],show_normed = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
